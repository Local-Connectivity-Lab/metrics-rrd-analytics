{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f64d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## Stdlib\n",
    "\n",
    "## Non-std libs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "## Local modules\n",
    "from scn_rrd import config, librenms_meta_utils, librenms_rrd_utils, rrd_utils, plot_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cce33a",
   "metadata": {},
   "source": [
    "### Data rate consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd4a9b",
   "metadata": {},
   "source": [
    "Investigating the unit of data in the RRD:\n",
    "\n",
    "- https://oidref.com/1.3.6.1.2.1.2.2.1.10 shows that the snmp metric is for total number of bytes ever received/sent by a given interface. (The value decreases across time iff overflow.)\n",
    "- LibreNMS does its magical php things and stores inOctets and outOctets metrics at `/opt/librenms/rrd/<device_ip_or_hostname>/port-<port_id>.rrd`\n",
    "- `rrdtool info ..../port-<port_id>.rrd` shows that these RRD database's `INOCTETS` and `OUTOCTETS` DSes are of type `DERIVE`.\n",
    "- Queries:\n",
    "    - In response to `rrdtool fetch ..../port-<port_id>.rrd AVERAGE ...`:\n",
    "        - Each value has the unit of Bytes/second and encodes the average(measured data rates within one time resolution).\n",
    "    - In response to `rrdtool fetch ..../port-<port_id>.rrd MAX ...`:\n",
    "        - Each value has the unit of Bytes/second and encodes the max(measured data rates within one time resolution).\n",
    "    - The time resolution can optionally by specified as a command line arg; or, it's dynamically chosen according to the queried time span.\n",
    "- Validation of the above interpretation:\n",
    "    - We can compare various graphs generated by LibreNMS using `rrdgraph`.\n",
    "        - Eg:\n",
    "            1. `DEF:inoctets=Garfield-EPC/port-id190.rrd:INOCTETS:AVERAGE`\n",
    "            1. `VDEF:totin=inoctets,TOTAL`\n",
    "            1. According to https://oss.oetiker.ch/rrdtool/doc/rrdgraph_rpn.en.html#TOTAL, `TOTAL` multiplies logged values by the time resolution.\n",
    "            1. `GPRINT:totin:'\\(In %6.2lf%sB'    ...`\n",
    "            1. The `TOTAL` aggregator yields Bytes. Hence, we can infer that each value yielded by `AVERAGE` is Bytes/sec, and to get the total value, we calculate, in pseudocode, `sum(val * time_resolution for val in raw_AVERAGE_values)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede6d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "portGroups = [\n",
    "    'epc-backhaul-interface',\n",
    "    'backhaul-interface',\n",
    "]\n",
    "\n",
    "meta = librenms_meta_utils.read_meta()\n",
    "meta = meta[\n",
    "    ( meta['location'].isin(config.PHYS_LOCS) ) &\n",
    "    ( meta['port_group_name'].isin(portGroups) )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each device, there should be one interface/port that's tagged as \"backhaul interface\" on LibreNMS.\n",
    "len(meta['hostname'].unique()) == len(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f81057",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMS_HOST_IP = config.DOTENV_ENTRIES['NMS_HOST_IP']\n",
    "physLoc_to_consumeDf = dict()\n",
    "for (_, row) in meta.iterrows():\n",
    "    rrd_filename = librenms_rrd_utils.format_port_rrd_filename(row['port_id'])\n",
    "    rrd_filepath = librenms_rrd_utils.format_rrd_filepath(row['hostname'], rrd_filename)\n",
    "    df = rrd_utils.read_rrd(NMS_HOST_IP, rrd_filepath, '-3month')\n",
    "\n",
    "    physLoc = row['location']\n",
    "\n",
    "    physLoc_to_consumeDf[physLoc] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a2443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data.\n",
    "for (physLoc, consumeDf) in physLoc_to_consumeDf.items():\n",
    "    # We see unrealistic spikes in the retrieved data rates.\n",
    "    # The cause could be anything in the whole data pipeline, from snmp to our python code.\n",
    "    # Here, we choose an arbitrary threshold.\n",
    "    thresh = 1e8\n",
    "    consumeDf.loc[ consumeDf['INOCTETS'] > thresh, 'INOCTETS' ] = pd.NA\n",
    "    consumeDf.loc[ consumeDf['OUTOCTETS'] > thresh, 'OUTOCTETS' ] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee295345",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig, (ax_amount, ax_ratio)) = plt.subplots(nrows=2, figsize=(12, 6 * 2))\n",
    "for (physLoc, consumeDf) in physLoc_to_consumeDf.items():\n",
    "    resoln = (consumeDf['time'][1] - consumeDf['time'][0]).seconds\n",
    "    \n",
    "    # The conceptual value transformation goes like:\n",
    "    #     Raw value is average Bytes/sec within one time resolution\n",
    "    #     --(mult by time resolution)--> Bytes within one time resolution\n",
    "    #     --(sum by day)--> Bytes within one day\n",
    "    #     --(div by pow(2,30))--> GigaBytes within one day\n",
    "    factor = resoln / pow(2, 30)\n",
    "    aggr_df = (\n",
    "        consumeDf[['time', 'INOCTETS', 'OUTOCTETS']]\n",
    "        .groupby(by=pd.Grouper(key='time', freq='D'))\n",
    "        .sum(numeric_only=True)\n",
    "        * factor\n",
    "    )\n",
    "    \n",
    "    color = plot_utils.LOC_TO_COLOR[physLoc]\n",
    "    aggr_df['INOCTETS'].plot(ax=ax_amount, label=f\"{physLoc} downloads\", color=color, linestyle='solid')\n",
    "    aggr_df['OUTOCTETS'].plot(ax=ax_amount, label=f\"{physLoc} uploads\", color=color, linestyle='dashed')\n",
    "    \n",
    "    aggr_df['out_in_ratio'] = aggr_df['OUTOCTETS'] / aggr_df['INOCTETS']\n",
    "    aggr_df['out_in_ratio'].plot(ax=ax_ratio, label=physLoc, color=color)\n",
    "\n",
    "ax_amount.set_title('Daily consumption')\n",
    "ax_amount.set_ylabel('Gigabyte')\n",
    "ax_amount.set_xlabel('Day')\n",
    "ax_amount.legend()\n",
    "\n",
    "ax_ratio.set_title('Daily consumption, ratio of uploads vs downloads')\n",
    "ax_ratio.set_ylabel('Ratio')\n",
    "ax_ratio.set_xlabel('Day')\n",
    "ax_ratio.legend()\n",
    "\n",
    "None # Hide stdout output of the above line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a389d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig, (ax_amount, ax_ratio)) = plt.subplots(nrows=2, figsize=(12, 6 * 2))\n",
    "for (physLoc, consumeDf) in physLoc_to_consumeDf.items():\n",
    "    resoln = (consumeDf['time'][1] - consumeDf['time'][0]).seconds\n",
    "    days = ( max(consumeDf['time']) - min(consumeDf['time']) ).days + 1\n",
    "\n",
    "    # The conceptual value transformation goes like:\n",
    "    #     Raw value is average Bytes/sec within one time resolution\n",
    "    #     --(mult by time resolution)--> Bytes within one time resolution\n",
    "    #     --(sum by hour_of_day)--> Bytes within one hour_of_day across all days\n",
    "    #     --(div by ct of days)--> Bytes within one hour_of_day in one average day\n",
    "    #     --(div by pow(2,30))--> GigaBytes ditto\n",
    "    factor = resoln / pow(2, 30) / days\n",
    "    aggr_df = (\n",
    "        consumeDf[['time', 'INOCTETS', 'OUTOCTETS']]\n",
    "        .groupby(consumeDf['time'].dt.hour)\n",
    "        .sum(numeric_only=True)\n",
    "        * factor\n",
    "    )\n",
    "\n",
    "    color = plot_utils.LOC_TO_COLOR[physLoc]\n",
    "    aggr_df['INOCTETS'].plot(ax=ax_amount, label=f\"{physLoc} downloads\", color=color, linestyle='solid')\n",
    "    aggr_df['OUTOCTETS'].plot(ax=ax_amount, label=f\"{physLoc} uploads\", color=color, linestyle='dashed')\n",
    "    \n",
    "    aggr_df['out_in_ratio'] = aggr_df['OUTOCTETS'] / aggr_df['INOCTETS']\n",
    "    aggr_df['out_in_ratio'].plot(ax=ax_ratio, label=physLoc, color=color)\n",
    "\n",
    "ax_amount.set_title('Average hourly consumption')\n",
    "ax_amount.set_ylabel('Gigabyte')\n",
    "ax_amount.set_xlabel('Hour')\n",
    "ax_amount.legend()\n",
    "\n",
    "ax_ratio.set_title('Average hourly consumption, ratio of uploads vs downloads')\n",
    "ax_ratio.set_ylabel('Ratio')\n",
    "ax_ratio.set_xlabel('Day')\n",
    "ax_ratio.legend()\n",
    "\n",
    "ax_ratio.set_title('Average hourly consumption, ratio of uploads vs downloads')\n",
    "None # Hide stdout output of the above line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98915f7c",
   "metadata": {},
   "source": [
    "### Data rate capacity (aka speedtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affab743",
   "metadata": {},
   "outputs": [],
   "source": [
    "physLoc_to_capDf = dict()\n",
    "for (ip, physLoc) in config.MONITOR_DEVICES.items():\n",
    "    down_df = rrd_utils.read_rrd(ip, 'down_rate.rrd', '-3month')\n",
    "    up_df   = rrd_utils.read_rrd(ip, 'up_rate.rrd',   '-3month')\n",
    "\n",
    "    df = down_df.merge(up_df, on='time', how='outer')\n",
    "\n",
    "    physLoc_to_capDf[physLoc] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fig, ax) = plt.subplots(figsize=(12, 6))\n",
    "for phys_loc in config.MONITOR_DEVICES.values():\n",
    "    color = plot_utils.LOC_TO_COLOR[phys_loc]\n",
    "    \n",
    "    capDf = physLoc_to_capDf[phys_loc]\n",
    "    \n",
    "    ax.plot(capDf['time'], capDf['down_rate'], label=f\"{phys_loc} download\", color=color, linestyle='solid')\n",
    "    ax.plot(capDf['time'], capDf['up_rate'], label=f\"{phys_loc} upload\", color=color, linestyle='dashed')\n",
    "ax.set_title('Capacity')\n",
    "ax.set_ylabel('Mbps')\n",
    "ax.legend()\n",
    "None # Hide stdout output of the above line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001f5de",
   "metadata": {},
   "source": [
    "### Utilization == Consumption / Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57230023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utilization(consume_df: pd.DataFrame, capacity_df: pd.DataFrame, factor: float) -> pd.DataFrame:\n",
    "    '''\n",
    "    @arg consume_df and capacity_df:\n",
    "        Each DF should have two columns,\n",
    "        1st column containing time, and\n",
    "        2nd column containing quantity (float).\n",
    "    @return:\n",
    "        1st column contains time, unmodified from @arg consume_df.\n",
    "        2nd column contains (consumed quantity / capacity quantity),\n",
    "            where capacity quantity comes from the last measurement at or before the time.\n",
    "    '''\n",
    "    cap_i = 0\n",
    "    cap_n = len(capacity_df)\n",
    "    cap_quant_prev = None\n",
    "    \n",
    "    utilizn_rows = []\n",
    "    \n",
    "    for (_, (consu_time, consu_quant)) in consume_df.iterrows():\n",
    "        if pd.isna(consu_quant):\n",
    "            continue\n",
    "        \n",
    "        while cap_i < cap_n and capacity_df.iloc[cap_i][0] <= consu_time:\n",
    "            _cap_quant = capacity_df.iloc[cap_i][1]\n",
    "            if not pd.isna(_cap_quant):\n",
    "                cap_quant_prev = _cap_quant\n",
    "            cap_i += 1\n",
    "\n",
    "        if pd.isna(cap_quant_prev):\n",
    "            # No capacity was recorded before the current consumption timestamp.\n",
    "            continue\n",
    "\n",
    "        utilizn = consu_quant / cap_quant_prev * factor\n",
    "        utilizn_row = (consu_time, utilizn)\n",
    "        utilizn_rows.append(utilizn_row)\n",
    "\n",
    "    return pd.DataFrame(utilizn_rows, columns=['time', 'utilization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c33d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_ct = len(config.MONITOR_DEVICES)\n",
    "(fig, axez) = plt.subplots(nrows=mon_ct, figsize=(12, 3 * mon_ct), constrained_layout=True)\n",
    "for (ax, phys_loc) in zip(axez, config.MONITOR_DEVICES.values()):\n",
    "    logi_loc = config.PHYS_LOC_TO_LOGICAL_LOC[phys_loc]\n",
    "    \n",
    "    ## Get consumption at the monitoring device or at our LTE location.\n",
    "    consumeDf = physLoc_to_consumeDf.get(phys_loc, physLoc_to_consumeDf[logi_loc])\n",
    "    ## Get capacity at the monitoring device.\n",
    "    capDf = physLoc_to_capDf[phys_loc]\n",
    "    \n",
    "    # Scale both numerator and denominator to bitsPerSec. Then scale to percentage.\n",
    "    factor = (1/8) / pow(2,20) * 100\n",
    "    \n",
    "    color = plot_utils.LOC_TO_COLOR[phys_loc]\n",
    "\n",
    "    utilzn_df = utilization(consumeDf[['time', 'INOCTETS']], capDf[['time', 'down_rate']], factor)\n",
    "    ax.plot(utilzn_df['time'], utilzn_df['utilization'], label=f\"{phys_loc} download\", color=color, linestyle='solid')\n",
    "    \n",
    "    utilizn_df = utilization(consumeDf[['time', 'OUTOCTETS']], capDf[['time', 'up_rate']], factor)\n",
    "    ax.plot(utilzn_df['time'], utilzn_df['utilization'], label=f\"{phys_loc} upload\", color=color, linestyle='dashed')\n",
    "    \n",
    "    ax.set_ylabel('Percent')\n",
    "    ax.legend()\n",
    "fig.suptitle('Utilization')\n",
    "None # Hide stdout output of the above line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3045e808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
